ONH Expert Connector — Concept Summary (for Codex)

Purpose
- Help ONH teachers quickly find internal staff whose existing public profiles and publications match a course/topic/material.
- Output: names of relevant staff + concrete, evidence-based reasons (with links). No email templates or collaboration suggestions.

Users & Access
- Teacher: the only user. Uses the app with NO login.
- Admin: edits a simple staff list file in the codebase (staff.yaml). No UI for admins.
- Researchers/experts: do nothing in this app. The app only reads what they already publish publicly.

Inputs (Teacher)
- Topic text (one or more paragraphs describing course/material).
- Optional files: syllabus, slides, reading list (PDF/DOCX/PPTX/TXT/MD).
- Optional filter: department (campus and language are NOT used).

Outputs (Teacher)
- Ranked list of staff candidates (name + department).
- “Why matched” explanation: 2–4 sentences grounded in specific sentences/titles from their public profile or publication pages.
- Source links for each explanation.
- Shortlist function and export (PDF/JSON). No messaging or email generation.

Data Sources
- A single config file (staff.yaml) maintained in the repo by an admin. For each staff member:
  - name, department
  - profile_url
  - sources: array of allowed public URLs to fetch (e.g., ONH profile page, publication pages, ORCID/Scholar pages if public)
  - tags: list of expertise keywords (free text)
- Offline index builder fetches and stores snapshots of those sources inside `data/offline_snapshots/` (respecting the allowlist) and produces a local vector index under `data/index/`. The app never queries the open web at runtime.
- Admins rerun the index builder after editing `staff.yaml` or when sources change.

Matching Approach (RAG Backbone)
- Extract text from teacher input (and uploaded files), normalise it, derive editable topic keywords, and create a query embedding.
- Use the query embedding (plus optional department/tag filters) to retrieve the strongest passages from the local vector index. Chunks retain metadata about staff, department, source title, and URL.
- Re-rank at the staff level using aggregated similarity scores, tag overlap, department preference, and diversity nudges so a single team does not dominate.
- Explanations are generated by a small local LLM but constrained to the retrieved passages; the call includes chunk metadata so the model cites the evidence directly. Deterministic fallback stays in place if the LLM is unavailable.

UI Flow (Minimal)
1) Home
   - Text box for topic; file upload; Department filter dropdown.
   - Button: “Find matches”.
2) Review Themes
   - Shows extracted topic chips (editable). Button: “Search experts”.
3) Results
   - 5–10 cards: Name, Department, Why matched (+ links), Add to shortlist.
   - Left-side filters: Department only.
4) Shortlist
   - View, reorder, add notes. Export PDF/JSON.

Non-Goals (Deliberate Omissions)
- No user accounts or logins.
- No researcher/admin dashboards.
- No campus or language filter beyond the department filter.
- No “include methods experts” toggle.
- No email/message generation or outreach suggestions.

ONH-Specific Notes
- Tailored to Oslo Nye Høyskole, which publicly lists staff and research. The app relies on those public pages.
- Department filter retained to reflect ONH’s multiple disciplines (e.g., psychology, health, business/society).
- Language handling: mixed Norwegian/English texts are acceptable; we prioritize robust basic matching over language-specific features in the MVP.

Local Prototype & Models (RTX 4070 Friendly)
- Run locally on a machine with NVIDIA RTX 4070 (12 GB VRAM typical).
- LLM for explanations: small instruction-tuned model, e.g. Llama 3.2 3B Instruct (Q4) or Mistral 7B Instruct (Q4) via Ollama/llama.cpp.
- Embeddings: bge-small-en-v1.5 or all-MiniLM-L6-v2 (CPU or GPU).
- Vector store: FAISS/Chroma (embedded locally); keyword search remains as a backup using BM25 (e.g., rank_bm25) for resilience.
- Model swapping via models.yaml (change model name/quantization and restart).

Security & Privacy
- Local-only by default (binds to localhost unless configured).
- Strict fetch allowlist: only the URLs listed per staff entry are fetched; no crawling beyond these.
- Upload hygiene: block executables/macros, limit file types/size, antivirus scan.
- No student data: warn/block if detected.
- Store only minimal snippets/embeddings; set a cache retention window.

Config Files (Editable by Admin)
- staff.yaml: staff entries with profile URL(s), allowed source URLs, department, tags.
- models.yaml: model choices and quantization settings.
- app.config.yaml: limits (max sources/pages per staff, max KB per page, cache size, language options, export settings), plus RAG index parameters (chunk size, overlap, refresh cadence).
- data/index/: generated artifacts (vector store + metadata). Rebuild via CLI, not manual edits.

MVP Scope
- File/text parsing.
- Theme extraction (keywords + query embeddings).
- Offline index builder with allowlisted fetch, chunking, and embedding.
- Runtime retrieval against the local vector store + lightweight re-ranking.
- Grounded, linked explanations.
- Results UI (cards, filter) + shortlist/export.
- No external database; everything file/config-driven with on-disk indexes.

High-Level Endpoints (if building a small web service)
- POST /analyze-topic : accepts text + files; returns extracted themes.
- POST /match : accepts themes + optional department; performs fetch+match and returns ranked candidates with explanations + links.
- GET  /shortlist : returns saved shortlist (local session or file).
- POST /shortlist : saves/updates shortlist.
- GET  /config   : returns basic app settings (read-only for UI).

Success Criteria
- A teacher can paste a topic (or upload a syllabus), pick a department filter if needed, and receive a short ranked list of ONH colleagues with clear “why matched” reasons and links.
- Runs entirely on a local 4070 with small models.
- No logins. No researcher/admin UI. Admins only edit staff.yaml/models.yaml/app.config.yaml.
